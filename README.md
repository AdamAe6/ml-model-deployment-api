---
title: ML Model Deployment API
emoji: üß†
colorFrom: indigo
colorTo: blue
sdk: docker
python_version: "3.10"
app_port: 7860
pinned: false
---

# ML Model Deployment API

## R√©sum√©

API REST en FastAPI pour exposer un mod√®le de machine learning (format joblib).
Le service re√ßoit un dictionnaire de features, renvoie une pr√©diction binaire
(0/1) et la probabilit√© associ√©e. Les requ√™tes et r√©sultats peuvent √™tre
persist√©s en base (PostgreSQL) via SQLAlchemy.

## Contexte

Ce d√©p√¥t regroupe le code serveur, le mod√®le entra√Æn√© (joblib) et la couche
de persistance. Il a √©t√© d√©velopp√© dans le cadre du projet p√©dagogique
"D√©ployez votre mod√®le de Machine Learning".

## Technos principales

- Python 3.10+
- FastAPI (API)
- SQLAlchemy (ORM)
- joblib / scikit-learn (mod√®le)
- Pytest (tests)
- PostgreSQL (persistance)

## Arborescence cl√©

```
./
‚îú‚îÄ‚îÄ app/                 # code de l'application (routes, db, mod√®les ML)
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # point d'entr√©e FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ db/              # session et mod√®les SQLAlchemy
‚îÇ   ‚îî‚îÄ‚îÄ ml/              # loader et artefacts du mod√®le
‚îú‚îÄ‚îÄ docs/                # documentation/support (ex: db_schema.txt)
‚îú‚îÄ‚îÄ tests/               # tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ requirements.txt     # d√©pendances
‚îî‚îÄ‚îÄ README.md
```

## Installation locale

1. Cr√©ez un environnement Python (venv/conda) avec Python 3.10+. Exemple :

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2. Pr√©parez la base de donn√©es (PostgreSQL) et configurez la variable
   d'environnement `DATABASE_URL` (format SQLAlchemy). Exemple :

```bash
export DATABASE_URL="postgresql+psycopg2://user:pass@localhost:5432/dbname"
```

3. Cr√©ez les tables (si n√©cessaire) via le script `app/db/create_db.py` ou
   avec vos migrations (Alembic si ajout√©).

## Ex√©cution

Lancer le serveur en d√©veloppement :

```bash
uvicorn app.main:app --reload
```

## Endpoints

1. GET /health

- Description : v√©rifie que l'API est up.
- R√©ponse : 200 {"status":"ok"}

2. POST /predict

- Description : envoie un dictionnaire de features et re√ßoit la pr√©diction
  et la probabilit√©.
- Payload (JSON) :

```json
{
	"features": {
		"age": 35,
		"age_debut_carriere": 22,
		"annee_experience_totale": 13,
		... (toutes les features attendues) ...
	}
}
```

- R√©ponse (200) :

```json
{
  "prediction": 1,
  "probability": 0.78
}
```

## Validation et liste des features attendues

Le serveur valide la pr√©sence et la coh√©rence d'un ensemble de features
attendues (liste compl√®te dans `app/main.py` variable `EXPECTED_FEATURES`).
En cas de feature manquante ou incoh√©rence, l'API renvoie 400 avec le d√©tail
de l'erreur.

## Mod√®le

Le loader de mod√®le se trouve dans `app/ml/model.py` et charge
`app/ml/models/model_p4.joblib`. Assurez-vous que ce fichier existe et est
compatible (m√™me jeu de features et ordre). Si le mod√®le est introuvable,
un FileNotFoundError est lev√© au d√©marrage.

## Persistance (Base de donn√©es)

Le projet d√©finit deux tables principales (SQLAlchemy) :

- `model_inputs` : stocke l'objet JSON des features envoy√©es au mod√®le.
- `model_outputs`: stocke la pr√©diction, la probabilit√© et une r√©f√©rence
  vers `model_inputs`.

Extrait du sch√©ma (UML / PlantUML) :

```plantuml
@startuml
entity model_inputs {
	+ id : int
	--
	features : jsonb
	created_at : timestamp
}

entity model_outputs {
	+ id : int
	--
	prediction : int
	probability : float
	created_at : timestamp
}

model_inputs ||--o{ model_outputs : generates
@enduml
```

SQL (exemples simplifi√©s)

```sql
CREATE TABLE model_inputs (
	id SERIAL PRIMARY KEY,
	features JSONB NOT NULL,
	created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL
);

CREATE TABLE model_outputs (
	id SERIAL PRIMARY KEY,
	input_id INTEGER NOT NULL REFERENCES model_inputs(id) ON DELETE CASCADE,
	prediction INTEGER NOT NULL CHECK (prediction IN (0,1)),
	probability DOUBLE PRECISION NULL CHECK (probability >= 0 AND probability <= 1),
	created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL
);
```

## Quelques validations c√¥t√© ORM

La couche `app/db/models.py` contient des validations d√©taill√©es des
features (plages autoris√©es, coh√©rences entre √¢ge / exp√©rience / anciennet√©,
types, etc.). Ces r√®gles prot√®gent l'int√©grit√© des donn√©es persist√©es.

## Tests

Les tests unitaires se trouvent dans `tests/`. Pour lancer la suite :

```bash
pytest -q
```

## URL GitHub

[https://github.com/AdamAe6/ml-model-deployment-api](https://github.com/AdamAe6/ml-model-deployment-api)

## Roadmap & am√©liorations propos√©es

Ci-dessous des actions et recommandations √† ajouter √† la documentation / plan de d√©veloppement. Elles couvrent l'authentification pour le d√©ploiement sur Hugging Face Spaces via cl√© (int√©gr√©e dans GitHub Actions), les besoins analytiques, des am√©liorations du mod√®le et des endpoints additionnels, ainsi que des propositions de tables suppl√©mentaires pour la gestion des logs.

### 1) Authentification Hugging Face Space (mode cl√©) ‚Äî GitHub Actions

- Cr√©ez une cl√© d'acc√®s (Access Token) depuis votre compte Hugging Face (Settings -> Access Tokens) avec les droits n√©cessaires pour d√©ployer ou mettre √† jour votre Space.
- Stockez cette cl√© comme secret GitHub dans le d√©p√¥t : par exemple `HF_API_TOKEN` (Repository Settings -> Secrets and variables -> Actions -> New repository secret).
- Dans votre workflow GitHub Actions (ex. `.github/workflows/deploy.yml`), injectez le secret via `secrets.HF_API_TOKEN` et utilisez-le pour l'authentification lors de la phase de d√©ploiement. Exemple d'approche g√©n√©rique :

```yaml
# snippet d'exemple ‚Äî adaptez selon votre action de d√©ploiement
- name: Deploy to Hugging Face Space
	env:
		HF_API_TOKEN: ${{ secrets.HF_API_TOKEN }}
	run: |
		pip install huggingface_hub
		# exemple : script python qui pousse les artefacts sur le Space en utilisant HF_API_TOKEN
		python scripts/deploy_to_hf_space.py --token "$HF_API_TOKEN"
```

- Bonnes pratiques :
  - Ne jamais hardcoder la cl√© dans le repo. Utilisez les secrets GitHub.
  - V√©rifiez que les logs CI ne r√©v√®lent pas la variable (GitHub masque automatiquement les secrets mais soyez prudent avec les commandes `echo`).
  - Limitez la port√©e et la dur√©e du token si possible.

### 2) Besoins analytiques (telemetry / observability)

Proposer et instrumenter la collecte des m√©triques et logs suivants :

- √âv√©nements √† collecter :

  - Requ√™tes entrantes : route, timestamp, taille du payload, utilisateur (si authentifi√©), request_id
  - Latence par endpoint (ms)
  - Statistiques mod√®le : prediction, probability, mod√®le utilis√©/version
  - Erreurs/exceptions (stacktrace minimal, code HTTP)

- Donn√©es stock√©es pour chaque √©v√©nement (suggestion):

  - timestamp, request_id, route, model_version, input_hash, prediction, probability, latency_ms, status_code, user_id (anonymis√©)

- Architecture recommand√©e :
  - Logs structur√©s -> stocker dans Postgres (logs JSONB) ou envoyer vers un service de logs

### 3) Am√©lioration du mod√®le et autres endpoints ("Sharp")

Suggestions d'endpoints √† ajouter :

- `GET /version` : renvoie la version du mod√®le, date d'entra√Ænement et m√©tadonn√©es.
- `POST /explain` : endpoint d'explicabilit√© (SHAP) qui renvoie les contributions des features.

### 4) Tables suppl√©mentaires pour gestion des logs / audit

Proposition de sch√©ma minimal (PostgreSQL) pour capturer logs et audits :

1. `request_logs`

```sql
CREATE TABLE request_logs (
	id SERIAL PRIMARY KEY,
	request_id UUID NOT NULL,
	route TEXT NOT NULL,
	input_hash TEXT NULL,
	model_version TEXT NULL,
	status_code INTEGER NOT NULL,
	latency_ms INTEGER NULL,
	created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL,
	meta JSONB NULL
);
```

2. `error_logs`

```sql
CREATE TABLE error_logs (
	id SERIAL PRIMARY KEY,
	request_id UUID NULL,
	error_message TEXT NOT NULL,
	error_type TEXT NULL,
	stack TEXT NULL,
	created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL,
	meta JSONB NULL
);
```

3. `audit_logs`

```sql
CREATE TABLE audit_logs (
	id SERIAL PRIMARY KEY,
	actor TEXT NOT NULL,
	action TEXT NOT NULL,
	target TEXT NULL,
	details JSONB NULL,
	created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL
);
```
